{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/biglool/Hologram_Cell_detection/blob/main/notebooks/test%20rcnn/RPN_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnNb8NRjeRCs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm as tq\n",
        "\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "\n",
        "from tensorflow import data as tf_data\n",
        "from tensorflow import image as tf_image\n",
        "from tensorflow import io as tf_io\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import zipfile\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GzgagSXidGd",
        "outputId": "4a09c541-515c-404f-e510-9aefe11d14ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3blhbiRmhoUQ",
        "outputId": "148114cd-2db1-4a4f-9414-6eb9d66803e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Curro/Hologrames/Datos_sinteticos/Holo_subdiv/sub/1000_muestras_completas_small_count\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/gdrive/MyDrive/Curro/Hologrames/Datos_sinteticos/Holo_subdiv/sub/1000_muestras_completas_small_count'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNRvsuHwDEKk"
      },
      "source": [
        "FasterRcnn de pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRUzTVZgglCS"
      },
      "outputs": [],
      "source": [
        "def non_max_suppression(boxes, scores, max_boxes=50, iou_threshold=0.5):\n",
        "    idxs = np.argsort(scores)[::-1]\n",
        "    selected_idxs = []\n",
        "\n",
        "    while len(idxs) > 0:\n",
        "        selected_idx = idxs[0]\n",
        "        selected_idxs.append(selected_idx)\n",
        "        if len(selected_idxs) >= max_boxes:\n",
        "            break\n",
        "\n",
        "        idxs = idxs[1:]\n",
        "        filtered_idxs = []\n",
        "\n",
        "        for idx in idxs:\n",
        "            iou = calculate_iou(boxes[selected_idx], boxes[idx])\n",
        "            if iou < iou_threshold:\n",
        "                filtered_idxs.append(idx)\n",
        "\n",
        "        idxs = filtered_idxs\n",
        "\n",
        "    return selected_idxs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V48TG13iMi7Y"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "implementaciones otras loses para keras\n",
        "'''\n",
        "\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    smooth = 1.0\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return 1 - ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n",
        "\n",
        "# Register the custom loss function\n",
        "get_custom_objects().update({\"dice_coef_loss\": dice_coef_loss})\n",
        "\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "def tversky_loss(y_true, y_pred, alpha=0.5, beta=2):\n",
        "    # Convert predictions to probabilities\n",
        "    y_true = K.cast(y_true, 'float32')\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "\n",
        "    # Calculate true positives (TP), false positives (FP), and false negatives (FN)\n",
        "    tp = K.sum(y_true * y_pred, axis=-1)\n",
        "    fp = K.sum((1 - y_true) * y_pred, axis=-1)\n",
        "    fn = K.sum(y_true * (1 - y_pred), axis=-1)\n",
        "\n",
        "    # Calculate the Tversky index\n",
        "    tversky_index = (tp + K.epsilon()) / (tp + alpha * fp + beta * fn + K.epsilon())\n",
        "\n",
        "    # Return the Tversky loss\n",
        "    return 1 - tversky_index\n",
        "get_custom_objects().update({\"tversky_loss\": tversky_loss})\n",
        "\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "def iou(y_true, y_pred, smooth=1):\n",
        "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
        "    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=[1,2,3])\n",
        "    iou = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "    return iou\n",
        "get_custom_objects().update({\"iou\": iou})\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "def jaccard_loss(y_true, y_pred):\n",
        "    y_true = K.flatten(y_true)\n",
        "    y_pred = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true * y_pred)\n",
        "    union = K.sum(y_true) + K.sum(y_pred) - intersection\n",
        "    return 1 - (intersection + 1) / (union + 1)\n",
        "get_custom_objects().update({\"jaccard_loss\": jaccard_loss})\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "def pixel_accuracy(y_true, y_pred):\n",
        "    y_pred = K.round(y_pred)\n",
        "    correct_pixels = K.sum(K.cast(K.equal(y_true, y_pred), K.floatx()))\n",
        "    total_pixels = K.cast(K.prod(K.shape(y_true)), K.floatx())\n",
        "    return (correct_pixels / total_pixels)\n",
        "get_custom_objects().update({\"pixel_accuracy\": pixel_accuracy})\n",
        "\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "def specificity(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.int32)\n",
        "    y_pred = tf.cast(tf.round(y_pred), tf.int32)\n",
        "\n",
        "    # True Negatives\n",
        "    tn = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(y_pred, 0)), tf.float32))\n",
        "\n",
        "    # False Positives\n",
        "    fp = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(y_pred, 1)), tf.float32))\n",
        "\n",
        "    specificity = tn / (tn + fp + K.epsilon())\n",
        "    return specificity\n",
        "get_custom_objects().update({\"specificity\": specificity})\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "def focal_loss(y_true, y_pred):\n",
        "        gamma=2.,\n",
        "        alpha=0.25\n",
        "        y_true = tf.convert_to_tensor(y_true, dtype=tf.float32)\n",
        "        y_pred = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
        "\n",
        "        # Clip the prediction values to prevent NaNs\n",
        "        epsilon = K.epsilon()\n",
        "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
        "\n",
        "        # Compute cross-entropy loss\n",
        "        cross_entropy = -y_true * K.log(y_pred)\n",
        "\n",
        "        # Compute weight\n",
        "        weight = alpha * y_true * K.pow((1 - y_pred), gamma)\n",
        "\n",
        "        # Compute Focal Loss\n",
        "        loss = weight * cross_entropy\n",
        "        return K.sum(loss, axis=1)\n",
        "\n",
        "get_custom_objects().update({\"focal_loss\": focal_loss})\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "def combined_loss(y_true, y_pred):\n",
        "    # Binary cross-entropy loss\n",
        "    bce = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n",
        "\n",
        "    # Dice loss\n",
        "    dice = 1 - (2 * tf.reduce_sum(y_true * y_pred) + 1) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + 1)\n",
        "\n",
        "    return bce + dice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yh91E-WMszqK"
      },
      "outputs": [],
      "source": [
        "def generate_all_anchors(image_size, grid_size, base_size, ratios, scales):\n",
        "    \"\"\"\n",
        "    Generate all anchors for an entire grid on an image.\n",
        "    Args:\n",
        "    - image_size: (width, height) of the image\n",
        "    - grid_size: size of the grid (n_tiles_x, n_tiles_y)\n",
        "    - base_size: size of each tile (width and height)\n",
        "    - ratios: list of aspect ratios\n",
        "    - scales: list of scales\n",
        "    Returns:\n",
        "    - all_anchors: dictionary with tile indices as keys and list of anchors as values\n",
        "    \"\"\"\n",
        "    all_anchors = []#{}\n",
        "    for i in range(grid_size[0]):\n",
        "        for j in range(grid_size[1]):\n",
        "            center_x = i * base_size + base_size / 2\n",
        "            center_y = j * base_size + base_size / 2\n",
        "            anchors = generate_anchors_for_tile((center_x, center_y), base_size, ratios, scales, image_size)\n",
        "            #anchors=np.array(anchors).reshape(len(scales)*len(ratios),4)\n",
        "            #all_anchors[(i, j)] = anchors\n",
        "            for anchor in anchors: all_anchors.append(anchor)\n",
        "\n",
        "    return np.array(all_anchors)\n",
        "\n",
        "def generate_anchors_for_tile(center, base_size, ratios, scales, image_size):\n",
        "    \"\"\"\n",
        "    Generate anchor boxes centered on a specific point in the tile with boundary checks.\n",
        "    \"\"\"\n",
        "    anchors = []\n",
        "    for scale in scales:\n",
        "        for ratio in ratios:\n",
        "            w = base_size * scale * np.sqrt(ratio)\n",
        "            h = base_size * scale / np.sqrt(ratio)\n",
        "            x1 = center[0] - w / 2\n",
        "            y1 = center[1] - h / 2\n",
        "            x2 = center[0] + w / 2\n",
        "            y2 = center[1] + h / 2\n",
        "            x1, x2 = max(0, x1), min(image_size[0], x2)\n",
        "            y1, y2 = max(0, y1), min(image_size[1], y2)\n",
        "            anchors.append([x1, y1, x2, y2])\n",
        "    return anchors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "72_01EvUlGfd",
        "outputId": "b1dc5cae-b4cd-434f-d094-1a042af59a48"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import numpy as np\n",
        "\n",
        "def plot_anchors_on_image(image_size, all_anchors):\n",
        "    \"\"\"\n",
        "    Plot all anchors on an image.\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(1)\n",
        "    ax.set_xlim(0, image_size[0])\n",
        "    ax.set_ylim(0, image_size[1])\n",
        "    ax.set_aspect('equal')\n",
        "    ax.imshow(np.zeros(image_size), extent=(0, image_size[0], 0, image_size[1]), cmap='gray')\n",
        "\n",
        "    for (x1, y1, x2, y2) in all_anchors:\n",
        "        #for (x1, y1, x2, y2) in anchors:\n",
        "        ax.add_patch(patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=1, edgecolor='r', facecolor='none'))\n",
        "\n",
        "    plt.gca().invert_yaxis()  # Invert Y axis to match image coordinate system\n",
        "    plt.show()\n",
        "\n",
        "# Configuration\n",
        "image_size = (256, 256)\n",
        "grid_size = (32, 32)\n",
        "tile_size = 16\n",
        "ratios = [1]  # Aspect ratios\n",
        "scales = [ (1/4),(1/2),1,1.5]   # Scales based on the constraint\n",
        "\n",
        "# Generate all anchors\n",
        "all_anchors = generate_all_anchors(image_size, grid_size, tile_size, ratios, scales)\n",
        "\n",
        "# Plot the anchors\n",
        "plot_anchors_on_image(image_size, all_anchors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQppwdN7cEVY",
        "outputId": "b3253619-3ab0-4c5f-9eee-d4098e5b871c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of anchors: 4096\n",
            "0.19047619047619047\n",
            "Shape of y_rpn_cls: (4096, 1)\n",
            "Shape of y_rpn_regr: (4096, 4)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "def calculate_iou(box1, box2):\n",
        "    x1 = max(box1[0], box2[0])\n",
        "    y1 = max(box1[1], box2[1])\n",
        "    x2 = min(box1[2], box2[2])\n",
        "    y2 = min(box1[3], box2[3])\n",
        "\n",
        "    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
        "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "    union = box1_area + box2_area - intersection\n",
        "\n",
        "    return intersection / union\n",
        "\n",
        "def get_rpn_targets(anchors, gt_boxes, img_shape, pos_iou_thresh=0.5, neg_iou_thresh=0.5):\n",
        "    num_anchors = anchors.shape[0]\n",
        "    y_rpn_cls = np.zeros((num_anchors, 1), dtype=np.float32)\n",
        "    y_rpn_regr = np.zeros((num_anchors, 4), dtype=np.float32)\n",
        "    y_rpn_regr_unscaled = np.zeros((num_anchors, 4), dtype=np.float32)\n",
        "\n",
        "    for gt_box in gt_boxes:\n",
        "        best_iou = 0\n",
        "        best_anchor_idx = -1\n",
        "\n",
        "        for i in range(num_anchors):\n",
        "            anchor = anchors[i]\n",
        "            iou = calculate_iou(anchor, gt_box)\n",
        "            if iou > best_iou:\n",
        "                best_iou = iou\n",
        "                best_anchor_idx = i\n",
        "                print(best_iou)\n",
        "\n",
        "\n",
        "            if iou >= pos_iou_thresh:\n",
        "                y_rpn_cls[i] = 1\n",
        "                cx = (anchor[0] + anchor[2]) / 2\n",
        "                cy = (anchor[1] + anchor[3]) / 2\n",
        "                w = anchor[2] - anchor[0]\n",
        "                h = anchor[3] - anchor[1]\n",
        "\n",
        "                gt_cx = (gt_box[0] + gt_box[2]) / 2\n",
        "                gt_cy = (gt_box[1] + gt_box[3]) / 2\n",
        "                gt_w = gt_box[2] - gt_box[0]\n",
        "                gt_h = gt_box[3] - gt_box[1]\n",
        "\n",
        "                y_rpn_regr_unscaled[i, 0] = (gt_cx - cx) / w\n",
        "                y_rpn_regr_unscaled[i, 1] = (gt_cy - cy) / h\n",
        "                y_rpn_regr_unscaled[i, 2] = np.log(gt_w / w)\n",
        "                y_rpn_regr_unscaled[i, 3] = np.log(gt_h / h)\n",
        "\n",
        "        # Force assign the best anchor as positive if no anchors have sufficient IoU\n",
        "        if best_iou < pos_iou_thresh:\n",
        "            y_rpn_cls[best_anchor_idx] = 1\n",
        "            anchor = anchors[best_anchor_idx]\n",
        "            cx = (anchor[0] + anchor[2]) / 2\n",
        "            cy = (anchor[1] + anchor[3]) / 2\n",
        "            w = anchor[2] - anchor[0]\n",
        "            h = anchor[3] - anchor[1]\n",
        "\n",
        "            gt_cx = (gt_box[0] + gt_box[2]) / 2\n",
        "            gt_cy = (gt_box[1] + gt_box[3]) / 2\n",
        "            gt_w = gt_box[2] - gt_box[0]\n",
        "            gt_h = gt_box[3] - gt_box[1]\n",
        "\n",
        "            y_rpn_regr_unscaled[best_anchor_idx, 0] = (gt_cx - cx) / w\n",
        "            y_rpn_regr_unscaled[best_anchor_idx, 1] = (gt_cy - cy) / h\n",
        "            y_rpn_regr_unscaled[best_anchor_idx, 2] = np.log(gt_w / w)\n",
        "            y_rpn_regr_unscaled[best_anchor_idx, 3] = np.log(gt_h / h)\n",
        "\n",
        "    y_rpn_regr[:, 0] = y_rpn_regr_unscaled[:, 0] * 10.0\n",
        "    y_rpn_regr[:, 1] = y_rpn_regr_unscaled[:, 1] * 10.0\n",
        "    y_rpn_regr[:, 2] = y_rpn_regr_unscaled[:, 2] * 5.0\n",
        "    y_rpn_regr[:, 3] = y_rpn_regr_unscaled[:, 3] * 5.0\n",
        "\n",
        "    return y_rpn_cls, y_rpn_regr\n",
        "\n",
        "# Example usage\n",
        "# Configuration\n",
        "image_size = (256, 256)\n",
        "feature_map_shape = (32, 32)\n",
        "tile_size = 16\n",
        "ratios = [1]  # Aspect ratios\n",
        "scales = [ (1/4),(1/2),1,1.5]  # Scales based on the constraint\n",
        "\n",
        "# Generate all anchors\n",
        "anchors = generate_all_anchors(image_size, feature_map_shape, tile_size, ratios, scales)\n",
        "\n",
        "print(f\"Total number of anchors: {anchors.shape[0]}\")  # Should be 9216\n",
        "\n",
        "# Example ground truth boxes\n",
        "gt_boxes = np.array([[5, 5, 8, 8]])\n",
        "\n",
        "#\n",
        "\n",
        "# Generate RPN targets\n",
        "y_rpn_cls, y_rpn_regr = get_rpn_targets(anchors, gt_boxes, image_size)\n",
        "print(f\"Shape of y_rpn_cls: {y_rpn_cls.shape}\")  # Should be (9216, 1)\n",
        "print(f\"Shape of y_rpn_regr: {y_rpn_regr.shape}\")  # Should be (9216, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qp3Oip5dHxh"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, data_folder, ground_truth_folder, batch_size, img_shape, anchors, shuffle=True, max_examples=0):\n",
        "        self.data_folder = data_folder\n",
        "        self.ground_truth_folder = ground_truth_folder\n",
        "        self.batch_size = batch_size\n",
        "        self.img_shape = img_shape\n",
        "        self.anchors = anchors  # Anchors generated beforehand\n",
        "        self.shuffle = shuffle\n",
        "        self.data_files = sorted([f for f in os.listdir(data_folder)])\n",
        "        self.ground_truth_files = sorted([f for f in os.listdir(ground_truth_folder)])\n",
        "        self.indexes = np.arange(len(self.data_files))\n",
        "        self.max_examples = max_examples\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.max_examples == 0:\n",
        "            num_examples = len(self.data_files)\n",
        "        else:\n",
        "            num_examples = min(self.max_examples, len(self.data_files))\n",
        "        return int(np.floor(num_examples / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        batch_data_files = [self.data_files[k] for k in batch_indexes]\n",
        "        batch_ground_truth_files = [self.ground_truth_files[k] for k in batch_indexes]\n",
        "\n",
        "        X, y_rpn_cls, y_rpn_regr = self.__data_generation(batch_data_files, batch_ground_truth_files)\n",
        "\n",
        "        return X, [y_rpn_cls, y_rpn_regr]\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def scale_array(self, array):\n",
        "        min_val = np.min(array)\n",
        "        max_val = np.max(array)\n",
        "        scaled_array = 2 * (array - min_val) / (max_val - min_val) - 1\n",
        "        return scaled_array\n",
        "\n",
        "    def __data_generation(self, batch_data_files, batch_ground_truth_files):\n",
        "        X = np.empty((self.batch_size, *self.img_shape), dtype='float32')\n",
        "        y_rpn_cls = np.zeros((self.batch_size, self.anchors.shape[0], 1), dtype='float32')  # Adjust dimensions as per your RPN output\n",
        "        y_rpn_regr = np.zeros((self.batch_size, self.anchors.shape[0], 4), dtype='float32')  # Adjust dimensions as per your RPN output\n",
        "\n",
        "        for i, (data_file, gt_file) in enumerate(zip(batch_data_files, batch_ground_truth_files)):\n",
        "            data_array = np.loadtxt(os.path.join(self.data_folder, data_file))\n",
        "            data_array = self.scale_array(data_array)\n",
        "            data_array = data_array.reshape(self.img_shape)\n",
        "\n",
        "            with open(os.path.join(self.ground_truth_folder, gt_file), 'rb') as f:\n",
        "                ground_truth_list = pickle.load(f)\n",
        "                processed_ground_truth = []\n",
        "                for obj in ground_truth_list:\n",
        "                    rad = obj[3]\n",
        "                    x1 = obj[0] - rad\n",
        "                    y1 = obj[1] - rad\n",
        "                    x2 = obj[0] + rad\n",
        "                    y2 = obj[1] + rad\n",
        "                    processed_ground_truth.append([x1, y1, x2, y2])\n",
        "\n",
        "            X[i,] = data_array\n",
        "\n",
        "            # Use pre-generated anchors for RPN targets\n",
        "            y_rpn_cls[i], y_rpn_regr[i] = get_rpn_targets(self.anchors, np.array(processed_ground_truth), self.img_shape)\n",
        "\n",
        "        return X, y_rpn_cls, y_rpn_regr\n",
        "\n",
        "\n",
        "# Example usage\n",
        "data_folder = 'mascaras'  # Modify as per your directory structure\n",
        "ground_truth_folder = 'parametros'  # Modify as per your directory structure\n",
        "img_shape = (256, 256, 1)\n",
        "batch_size = 16\n",
        "\n",
        "# Example anchors (generate these beforehand)\n",
        "anchors = generate_all_anchors(image_size=img_shape, grid_size=(32, 32), base_size=16, ratios=[1], scales=[0.25, 0.5, 1.0, 1.5])\n",
        "\n",
        "# Create data generators for training, validation, and test sets\n",
        "train_gen = DataGenerator(data_folder+\"/train/\", ground_truth_folder+\"/train/\", batch_size, img_shape, anchors, shuffle=True)\n",
        "val_gen = DataGenerator(data_folder+\"/val/\", ground_truth_folder+\"/val/\", batch_size, img_shape, anchors, shuffle=False)\n",
        "test_gen = DataGenerator(data_folder+\"/test/\", ground_truth_folder+\"/test/\", batch_size, img_shape, anchors, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OC0Cg3IgA1l",
        "outputId": "70edf2eb-8262-46d3-d71a-2fcd7bc32769"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"rpn_model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 256, 256, 16)         160       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 128, 128, 16)         0         ['conv2d[0][0]']              \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 128, 128, 16)         0         ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 128, 128, 32)         4640      ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 64, 64, 32)           0         ['conv2d_1[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 64, 64, 32)           0         ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 64, 64, 64)           18496     ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 32, 32, 64)           0         ['conv2d_2[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 32, 32, 64)           0         ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 128)          73856     ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " rpn_cls (Conv2D)            (None, 32, 32, 4)            516       ['conv2d_3[0][0]']            \n",
            "                                                                                                  \n",
            " rpn_cls_sigmoid (Activatio  (None, 32, 32, 4)            0         ['rpn_cls[0][0]']             \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " rpn_regr (Conv2D)           (None, 32, 32, 16)           2064      ['conv2d_3[0][0]']            \n",
            "                                                                                                  \n",
            " rpn_cls_reshape (Reshape)   (None, 4096, 1)              0         ['rpn_cls_sigmoid[0][0]']     \n",
            "                                                                                                  \n",
            " rpn_regr_reshape (Reshape)  (None, 4096, 4)              0         ['rpn_regr[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 99732 (389.58 KB)\n",
            "Trainable params: 99732 (389.58 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, Activation, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.models import load_model\n",
        "\n",
        "def rpn_model(image_shape, num_anchors):\n",
        "    inputs = Input(shape=image_shape, name='input_image')\n",
        "\n",
        "\n",
        "    # Load the pre-trained model\n",
        "    pretrain_model = load_model('Basic.keras')\n",
        "    # Use the 5 conv netwoerk as output\n",
        "    output = pretrain_model.layers[-8].output\n",
        "\n",
        "    # Create a new model with the desired output\n",
        "    rebuild_model = Model(inputs=pretrain_model.input, outputs=output)\n",
        "\n",
        "    # Print the summary of the new model\n",
        "    #for layer in rebuild_model.layers:\n",
        "        #layer.trainable = False\n",
        "\n",
        "    x = rebuild_model.output\n",
        "\n",
        "    # RPN classification layer\n",
        "    rpn_cls = Conv2D(num_anchors * 1, (1, 1), activation='linear', name='rpn_cls')(x)\n",
        "    rpn_cls = Activation('sigmoid', name='rpn_cls_sigmoid')(rpn_cls)\n",
        "    rpn_cls = Reshape((-1, 1), name='rpn_cls_reshape')(rpn_cls)\n",
        "\n",
        "    # RPN regression layer\n",
        "    rpn_regr = Conv2D(num_anchors * 4, (1, 1), activation='linear', name='rpn_regr')(x)\n",
        "    rpn_regr = Reshape((-1, 4), name='rpn_regr_reshape')(rpn_regr)\n",
        "\n",
        "    model = Model(inputs=rebuild_model.input, outputs=[rpn_cls, rpn_regr], name='rpn_model')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage\n",
        "image_shape = (256, 256, 1)  # Example image shape (height, width, channels)\n",
        "num_anchors = 4  # Number of anchors per feature map location (depending on ratios and scales)\n",
        "\n",
        "# Create RPN model\n",
        "rpn_model = rpn_model(image_shape, num_anchors)\n",
        "\n",
        "# Compile RPN model\n",
        "rpn_model.compile(optimizer='adam', loss={'rpn_cls_reshape': 'binary_crossentropy', 'rpn_regr_reshape': 'mse'})\n",
        "\n",
        "# Print model summary\n",
        "rpn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuF0ciEkj3E0",
        "outputId": "5dc0a8e7-c8c5-45c7-d9a0-96325cfb9853"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0832 - rpn_cls_reshape_loss: 0.0466 - rpn_regr_reshape_loss: 0.0174\n",
            "Epoch 1: val_loss improved from inf to 0.02327, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 489s 2s/step - loss: 0.0832 - rpn_cls_reshape_loss: 0.0466 - rpn_regr_reshape_loss: 0.0174 - val_loss: 0.0233 - val_rpn_cls_reshape_loss: 0.0075 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 2/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0208 - rpn_cls_reshape_loss: 0.0070 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 2: val_loss improved from 0.02327 to 0.01920, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 485s 2s/step - loss: 0.0208 - rpn_cls_reshape_loss: 0.0070 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0192 - val_rpn_cls_reshape_loss: 0.0070 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 3/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0178 - rpn_cls_reshape_loss: 0.0067 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 3: val_loss improved from 0.01920 to 0.01683, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 485s 2s/step - loss: 0.0178 - rpn_cls_reshape_loss: 0.0067 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0168 - val_rpn_cls_reshape_loss: 0.0067 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 4/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0159 - rpn_cls_reshape_loss: 0.0065 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 4: val_loss improved from 0.01683 to 0.01525, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 486s 2s/step - loss: 0.0159 - rpn_cls_reshape_loss: 0.0065 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0152 - val_rpn_cls_reshape_loss: 0.0065 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 5/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0146 - rpn_cls_reshape_loss: 0.0064 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 5: val_loss improved from 0.01525 to 0.01400, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 485s 2s/step - loss: 0.0146 - rpn_cls_reshape_loss: 0.0064 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0140 - val_rpn_cls_reshape_loss: 0.0063 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 6/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0134 - rpn_cls_reshape_loss: 0.0062 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 6: val_loss improved from 0.01400 to 0.01293, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 484s 2s/step - loss: 0.0134 - rpn_cls_reshape_loss: 0.0062 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0129 - val_rpn_cls_reshape_loss: 0.0062 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 7/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0125 - rpn_cls_reshape_loss: 0.0061 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 7: val_loss improved from 0.01293 to 0.01212, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 485s 2s/step - loss: 0.0125 - rpn_cls_reshape_loss: 0.0061 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0121 - val_rpn_cls_reshape_loss: 0.0061 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 8/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0118 - rpn_cls_reshape_loss: 0.0060 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 8: val_loss improved from 0.01212 to 0.01157, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 484s 2s/step - loss: 0.0118 - rpn_cls_reshape_loss: 0.0060 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0116 - val_rpn_cls_reshape_loss: 0.0060 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 9/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0113 - rpn_cls_reshape_loss: 0.0059 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 9: val_loss improved from 0.01157 to 0.01119, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 483s 2s/step - loss: 0.0113 - rpn_cls_reshape_loss: 0.0059 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0112 - val_rpn_cls_reshape_loss: 0.0059 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 10/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0110 - rpn_cls_reshape_loss: 0.0058 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 10: val_loss improved from 0.01119 to 0.01091, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 483s 2s/step - loss: 0.0110 - rpn_cls_reshape_loss: 0.0058 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0109 - val_rpn_cls_reshape_loss: 0.0058 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 11/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0108 - rpn_cls_reshape_loss: 0.0058 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 11: val_loss improved from 0.01091 to 0.01068, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 483s 2s/step - loss: 0.0108 - rpn_cls_reshape_loss: 0.0058 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0107 - val_rpn_cls_reshape_loss: 0.0058 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 12/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0106 - rpn_cls_reshape_loss: 0.0057 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 12: val_loss improved from 0.01068 to 0.01054, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 484s 2s/step - loss: 0.0106 - rpn_cls_reshape_loss: 0.0057 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0105 - val_rpn_cls_reshape_loss: 0.0057 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 13/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0105 - rpn_cls_reshape_loss: 0.0057 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 13: val_loss improved from 0.01054 to 0.01046, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 483s 2s/step - loss: 0.0105 - rpn_cls_reshape_loss: 0.0057 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0105 - val_rpn_cls_reshape_loss: 0.0057 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 14/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0104 - rpn_cls_reshape_loss: 0.0056 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 14: val_loss improved from 0.01046 to 0.01034, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 485s 2s/step - loss: 0.0104 - rpn_cls_reshape_loss: 0.0056 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0103 - val_rpn_cls_reshape_loss: 0.0057 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 15/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0103 - rpn_cls_reshape_loss: 0.0056 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 15: val_loss improved from 0.01034 to 0.01028, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 483s 2s/step - loss: 0.0103 - rpn_cls_reshape_loss: 0.0056 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0103 - val_rpn_cls_reshape_loss: 0.0056 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 16/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0102 - rpn_cls_reshape_loss: 0.0056 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 16: val_loss improved from 0.01028 to 0.01024, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 483s 2s/step - loss: 0.0102 - rpn_cls_reshape_loss: 0.0056 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0102 - val_rpn_cls_reshape_loss: 0.0056 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 17/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0103 - rpn_cls_reshape_loss: 0.0056 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 17: val_loss improved from 0.01024 to 0.01019, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 484s 2s/step - loss: 0.0103 - rpn_cls_reshape_loss: 0.0056 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0102 - val_rpn_cls_reshape_loss: 0.0056 - val_rpn_regr_reshape_loss: 0.0045\n",
            "Epoch 18/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0101 - rpn_cls_reshape_loss: 0.0055 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 18: val_loss improved from 0.01019 to 0.01016, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 484s 2s/step - loss: 0.0101 - rpn_cls_reshape_loss: 0.0055 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0102 - val_rpn_cls_reshape_loss: 0.0056 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 19/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0101 - rpn_cls_reshape_loss: 0.0055 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 19: val_loss improved from 0.01016 to 0.01014, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 485s 2s/step - loss: 0.0101 - rpn_cls_reshape_loss: 0.0055 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0101 - val_rpn_cls_reshape_loss: 0.0056 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 20/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0101 - rpn_cls_reshape_loss: 0.0055 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 20: val_loss improved from 0.01014 to 0.01012, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 485s 2s/step - loss: 0.0101 - rpn_cls_reshape_loss: 0.0055 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0101 - val_rpn_cls_reshape_loss: 0.0055 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 21/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0101 - rpn_cls_reshape_loss: 0.0055 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 21: val_loss improved from 0.01012 to 0.01011, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 484s 2s/step - loss: 0.0101 - rpn_cls_reshape_loss: 0.0055 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0101 - val_rpn_cls_reshape_loss: 0.0055 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 22/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0101 - rpn_cls_reshape_loss: 0.0055 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 22: val_loss improved from 0.01011 to 0.01009, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 484s 2s/step - loss: 0.0101 - rpn_cls_reshape_loss: 0.0055 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0101 - val_rpn_cls_reshape_loss: 0.0055 - val_rpn_regr_reshape_loss: 0.0045\n",
            "Epoch 23/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0101 - rpn_cls_reshape_loss: 0.0055 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 23: val_loss improved from 0.01009 to 0.01009, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 483s 2s/step - loss: 0.0101 - rpn_cls_reshape_loss: 0.0055 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0101 - val_rpn_cls_reshape_loss: 0.0055 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 24/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0101 - rpn_cls_reshape_loss: 0.0055 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 24: val_loss improved from 0.01009 to 0.01008, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 483s 2s/step - loss: 0.0101 - rpn_cls_reshape_loss: 0.0055 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0101 - val_rpn_cls_reshape_loss: 0.0055 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 25/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0100 - rpn_cls_reshape_loss: 0.0055 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 25: val_loss improved from 0.01008 to 0.01006, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 484s 2s/step - loss: 0.0100 - rpn_cls_reshape_loss: 0.0055 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0101 - val_rpn_cls_reshape_loss: 0.0055 - val_rpn_regr_reshape_loss: 0.0045\n",
            "Epoch 26/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0100 - rpn_cls_reshape_loss: 0.0055 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 26: val_loss did not improve from 0.01006\n",
            "300/300 [==============================] - 484s 2s/step - loss: 0.0100 - rpn_cls_reshape_loss: 0.0055 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0101 - val_rpn_cls_reshape_loss: 0.0055 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 27/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0100 - rpn_cls_reshape_loss: 0.0055 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 27: val_loss improved from 0.01006 to 0.01006, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 483s 2s/step - loss: 0.0100 - rpn_cls_reshape_loss: 0.0055 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0101 - val_rpn_cls_reshape_loss: 0.0055 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 28/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0100 - rpn_cls_reshape_loss: 0.0055 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 28: val_loss did not improve from 0.01006\n",
            "300/300 [==============================] - 484s 2s/step - loss: 0.0100 - rpn_cls_reshape_loss: 0.0055 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0101 - val_rpn_cls_reshape_loss: 0.0055 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 29/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0100 - rpn_cls_reshape_loss: 0.0055 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 29: val_loss improved from 0.01006 to 0.01006, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 483s 2s/step - loss: 0.0100 - rpn_cls_reshape_loss: 0.0055 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0101 - val_rpn_cls_reshape_loss: 0.0055 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 30/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0100 - rpn_cls_reshape_loss: 0.0055 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 30: val_loss improved from 0.01006 to 0.01005, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 482s 2s/step - loss: 0.0100 - rpn_cls_reshape_loss: 0.0055 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0100 - val_rpn_cls_reshape_loss: 0.0055 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 31/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 31: val_loss did not improve from 0.01005\n",
            "300/300 [==============================] - 481s 2s/step - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0101 - val_rpn_cls_reshape_loss: 0.0055 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 32/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 32: val_loss improved from 0.01005 to 0.01004, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 482s 2s/step - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0100 - val_rpn_cls_reshape_loss: 0.0055 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 33/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 33: val_loss did not improve from 0.01004\n",
            "300/300 [==============================] - 482s 2s/step - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0101 - val_rpn_cls_reshape_loss: 0.0055 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 34/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 34: val_loss improved from 0.01004 to 0.01004, saving model to best_rpn_model.keras\n",
            "300/300 [==============================] - 483s 2s/step - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0100 - val_rpn_cls_reshape_loss: 0.0055 - val_rpn_regr_reshape_loss: 0.0045\n",
            "Epoch 35/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 35: val_loss did not improve from 0.01004\n",
            "300/300 [==============================] - 482s 2s/step - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0100 - val_rpn_cls_reshape_loss: 0.0055 - val_rpn_regr_reshape_loss: 0.0045\n",
            "Epoch 36/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 36: val_loss did not improve from 0.01004\n",
            "300/300 [==============================] - 482s 2s/step - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0100 - val_rpn_cls_reshape_loss: 0.0055 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 37/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 37: val_loss did not improve from 0.01004\n",
            "300/300 [==============================] - 482s 2s/step - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0101 - val_rpn_cls_reshape_loss: 0.0055 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 38/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 38: val_loss did not improve from 0.01004\n",
            "300/300 [==============================] - 482s 2s/step - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0101 - val_rpn_cls_reshape_loss: 0.0055 - val_rpn_regr_reshape_loss: 0.0045\n",
            "Epoch 39/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 39: val_loss did not improve from 0.01004\n",
            "300/300 [==============================] - 482s 2s/step - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0100 - val_rpn_cls_reshape_loss: 0.0055 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 40/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 40: val_loss did not improve from 0.01004\n",
            "300/300 [==============================] - 482s 2s/step - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0100 - val_rpn_cls_reshape_loss: 0.0055 - val_rpn_regr_reshape_loss: 0.0045\n",
            "Epoch 41/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 41: val_loss did not improve from 0.01004\n",
            "300/300 [==============================] - 482s 2s/step - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0100 - val_rpn_cls_reshape_loss: 0.0055 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 42/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 42: val_loss did not improve from 0.01004\n",
            "300/300 [==============================] - 483s 2s/step - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0100 - val_rpn_cls_reshape_loss: 0.0055 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 43/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 43: val_loss did not improve from 0.01004\n",
            "300/300 [==============================] - 483s 2s/step - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0100 - val_rpn_cls_reshape_loss: 0.0055 - val_rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 44/100\n",
            "300/300 [==============================] - ETA: 0s - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046\n",
            "Epoch 44: val_loss did not improve from 0.01004\n",
            "300/300 [==============================] - 483s 2s/step - loss: 0.0100 - rpn_cls_reshape_loss: 0.0054 - rpn_regr_reshape_loss: 0.0046 - val_loss: 0.0100 - val_rpn_cls_reshape_loss: 0.0055 - val_rpn_regr_reshape_loss: 0.0046\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "\n",
        "# Define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('best_rpn_model2.keras', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
        "\n",
        "# Compile RPN model\n",
        "rpn_model.compile(optimizer='adam', loss={'rpn_cls_reshape': 'binary_crossentropy', 'rpn_regr_reshape': 'mse'})\n",
        "\n",
        "# Fit model with training and validation data, including callbacks\n",
        "rpn_model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=100,\n",
        "    steps_per_epoch=len(train_gen),\n",
        "    validation_steps=len(val_gen),\n",
        "    callbacks=[early_stopping, checkpoint]\n",
        ")\n",
        "\n",
        "\n",
        "# Save final trained model\n",
        "rpn_model.save('final_rpn_model2.keras')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,val in enumerate(val_gen.__getitem__(0)):\n"
      ],
      "metadata": {
        "id": "fXnrSo_FZu5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5gZiEr4nxHg",
        "outputId": "2c8227d0-5d36-46bb-cb05-c262067add78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "[[1.5208215e-06]\n",
            " [6.2999585e-05]\n",
            " [1.0081759e-03]\n",
            " ...\n",
            " [6.4024214e-05]\n",
            " [1.0199103e-03]\n",
            " [2.5098474e-04]]\n",
            "[[-5.9943274e-04  1.9880291e-03  2.7971528e-04 -8.1455521e-04]\n",
            " [ 1.5314892e-03 -9.5396116e-04 -3.2892134e-03  3.5421681e-03]\n",
            " [ 9.8318979e-04  2.7908050e-03  2.3118546e-04 -9.6072443e-04]\n",
            " ...\n",
            " [ 1.2879446e-03 -9.5357001e-04 -2.9740464e-03  3.2615280e-03]\n",
            " [ 1.2342632e-03  2.3065470e-03  5.6078658e-05 -1.2341440e-03]\n",
            " [-6.5822015e-04  2.7367277e-03  2.9293764e-03 -6.8039447e-04]]\n",
            "[0.00064144]\n",
            "[-0.0015523   0.00225445 -0.00076039 -0.00017583]\n",
            "[ 2.5       -2.5       -3.9007928 -3.9007928]\n",
            "[0.00221145]\n",
            "[ 0.00032534  0.00221977 -0.00350276 -0.00272693]\n",
            "[ 1.25       4.84375   -2.3500183 -2.3500183]\n",
            "[0.00221145]\n",
            "[ 0.00032534  0.00221977 -0.00350276 -0.00272693]\n",
            "[-2.1875    -3.75      -1.4384104 -1.4384104]\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "pretrain_rpn_model = load_model('best_rpn_model.keras')\n",
        "\n",
        "results=pretrain_rpn_model.predict(val_gen.__getitem__(0)[0])\n",
        "cls_res=results[0][0]\n",
        "reg_res=results[1][0]\n",
        "print(cls_res)\n",
        "print(reg_res)\n",
        "for i,val in enumerate(val_gen.__getitem__(0)[1][0][0]):\n",
        "  if val==1:\n",
        "    print(cls_res[i])\n",
        "    print(reg_res[i])\n",
        "    print(val_gen.__getitem__(0)[1][1][0][i])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWgTXLSdJcHE",
        "outputId": "6e108633-4aa6-4dee-a027-f170e27a3671"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-frcnn'...\n",
            "remote: Enumerating objects: 635, done.\u001b[K\n",
            "remote: Total 635 (delta 0), reused 0 (delta 0), pack-reused 635\u001b[K\n",
            "Receiving objects: 100% (635/635), 187.79 KiB | 1.46 MiB/s, done.\n",
            "Resolving deltas: 100% (433/433), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/kbardool/keras-frcnn.git"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOh+tvG9lC/yEpz1m/iQFSU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}